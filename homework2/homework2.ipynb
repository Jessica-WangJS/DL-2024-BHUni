{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZPAlhE5yv__6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c180e9ec-f081-4e3c-baf5-65b8445fbe26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./mount; to attempt to forcibly remount, call drive.mount(\"./mount\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./mount')\n",
        "# './mount/My Drive/Colab Notebooks/BH/1-2/DL/1/chinese_corpus/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "RIra9HBupEkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from sklearn.svm import SVC  # 以SVM作为分类器示例\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import random\n",
        "import string\n",
        "from gensim import corpora, models\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "\n",
        "def load_stopwords(file_path):\n",
        "    stop_words = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        stop_words.extend([word.strip('\\n') for word in f.readlines()])\n",
        "    return stop_words\n",
        "\n",
        "def preprocess_corpus(text, cn_stopwords):\n",
        "    for tmp_char in cn_stopwords:\n",
        "        text = text.replace(tmp_char, \"\")\n",
        "    return text\n",
        "\n",
        "def extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value):\n",
        "    result = []\n",
        "    total_paragraphs_count = sum(len(corpus_dict[novel]) for novel in corpus_dict)\n",
        "\n",
        "    if total_paragraphs_count < num_paragraphs:\n",
        "        print(f\"Warning: Only {total_paragraphs_count} paragraphs available in the corpus. Requested {num_paragraphs} will be returned.\")\n",
        "        num_paragraphs = total_paragraphs_count\n",
        "\n",
        "    # 统计每个小说的段落数量，用于均匀抽取\n",
        "    paragraph_counts = {novel: len(paragraphs) for novel, paragraphs in corpus_dict.items()}\n",
        "    # 均匀抽取指定数量的段落\n",
        "    for _ in range(num_paragraphs):\n",
        "        # 随机选择一个小说\n",
        "        novel = random.choices(list(corpus_dict.keys()), weights=[count / total_paragraphs_count for count in paragraph_counts.values()], k=1)[0]\n",
        "        # 从该小说中随机抽取一个段落\n",
        "        paragraphs = corpus_dict[novel]\n",
        "        paragraphs = re.split(r'\\n\\u3000\\u3000', paragraphs)\n",
        "        paragraph = random.choice(paragraphs)\n",
        "        # 根据 K 值范围，为该段落选择一个随机的 token 数量\n",
        "        # 对段落进行截断（如果需要），确保其包含指定数量的 token\n",
        "        tokens = list(jieba.cut(paragraph))\n",
        "        result.append((tokens, novel, k_value))\n",
        "    return result\n",
        "\n",
        "def LDA(processed_data, num_topics=10):\n",
        "    X = [item[0] for item in processed_data]  # 段落文本列表\n",
        "    y = [item[1] for item in processed_data]  # 段落所属小说标签列表\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 训练LDA模型\n",
        "    dictionary = corpora.Dictionary(X_train)\n",
        "    lda_corpus_train = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_train]\n",
        "    lda = models.LdaModel(corpus=lda_corpus_train, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "    train_topic_distribution = lda.get_document_topics(lda_corpus_train)\n",
        "\n",
        "    X_train_lda = np.zeros((len(X_train), num_topics))\n",
        "    for i in range(len(train_topic_distribution)):\n",
        "        tmp_topic_distribution = train_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_train_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "    classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "    lda_corpus_test = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_test]\n",
        "    test_topic_distribution = lda.get_document_topics(lda_corpus_test)\n",
        "    X_test_lda = np.zeros((len(X_test), num_topics))\n",
        "    for i in range(len(test_topic_distribution)):\n",
        "        tmp_topic_distribution = test_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_test_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    y_pred = classifier.predict(X_test_lda)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"F1 Score (Macro):\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 路径设置\n",
        "    stopwords_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/stopwords-zh.txt'\n",
        "    corpus_folder_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/chinese_corpus/'\n",
        "\n",
        "    # 加载停用词\n",
        "    cn_stopwords = load_stopwords(stopwords_file_path)\n",
        "\n",
        "    # 读取语料库\n",
        "    corpus_dict = {}  # Dictionary to store novel titles and contents\n",
        "    for file_name in os.listdir(corpus_folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            novel_title = os.path.splitext(file_name)[0]  # Extract novel title from file name\n",
        "            file_path = os.path.join(corpus_folder_path, file_name)  # Construct full file path\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                novel_content = f.read()\n",
        "            corpus_dict[novel_title] = novel_content\n",
        "\n",
        "    # 参数设置\n",
        "    num_paragraphs = 1000\n",
        "    k_value = 3000  # Choose the desired token count\n",
        "\n",
        "    # 定义不同的主题数量\n",
        "    topic_numbers = [5, 10, 15, 20]\n",
        "\n",
        "    # 遍历不同的主题数量\n",
        "    for num_topics in topic_numbers:\n",
        "        print(f\"Results for num_topics = {num_topics}:\")\n",
        "\n",
        "        # 执行主题建模和分类任务\n",
        "        processed_data = extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value)\n",
        "        LDA(processed_data, num_topics)\n"
      ],
      "metadata": {
        "id": "f5O4OOaapFxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774e26e4-9c64-433d-8a19-841b91c37b02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for num_topics = 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       书剑恩仇录       0.00      0.00      0.00        16\n",
            "         侠客行       0.00      0.00      0.00         7\n",
            "       倚天屠龙记       0.14      0.70      0.23        23\n",
            "        天龙八部       0.14      0.04      0.06        28\n",
            "       射雕英雄传       0.00      0.00      0.00        16\n",
            "       白马啸西风       0.00      0.00      0.00         2\n",
            "         碧血剑       0.00      0.00      0.00        13\n",
            "        神雕侠侣       0.00      0.00      0.00        18\n",
            "        笑傲江湖       0.00      0.00      0.00        31\n",
            "         越女剑       0.00      0.00      0.00         1\n",
            "         连城诀       0.00      0.00      0.00         4\n",
            "        雪山飞狐       0.00      0.00      0.00         4\n",
            "        飞狐外传       0.00      0.00      0.00        10\n",
            "         鸳鸯刀       0.00      0.00      0.00         1\n",
            "         鹿鼎记       0.11      0.31      0.16        26\n",
            "\n",
            "    accuracy                           0.12       200\n",
            "   macro avg       0.03      0.07      0.03       200\n",
            "weighted avg       0.05      0.12      0.05       200\n",
            "\n",
            "Accuracy: 0.125\n",
            "F1 Score (Macro): 0.029500603555796312\n",
            "Results for num_topics = 10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      三十三剑客图       0.00      0.00      0.00         1\n",
            "       书剑恩仇录       0.00      0.00      0.00        11\n",
            "         侠客行       0.00      0.00      0.00         7\n",
            "       倚天屠龙记       0.00      0.00      0.00        14\n",
            "        天龙八部       0.00      0.00      0.00        33\n",
            "       射雕英雄传       0.00      0.00      0.00        21\n",
            "       白马啸西风       0.00      0.00      0.00         1\n",
            "         碧血剑       0.00      0.00      0.00        12\n",
            "        神雕侠侣       0.27      0.44      0.33        27\n",
            "        笑傲江湖       0.00      0.00      0.00        25\n",
            "         连城诀       0.00      0.00      0.00         3\n",
            "        雪山飞狐       0.00      0.00      0.00         4\n",
            "        飞狐外传       0.00      0.00      0.00        10\n",
            "         鹿鼎记       0.19      0.94      0.32        31\n",
            "\n",
            "    accuracy                           0.20       200\n",
            "   macro avg       0.03      0.10      0.05       200\n",
            "weighted avg       0.07      0.20      0.09       200\n",
            "\n",
            "Accuracy: 0.205\n",
            "F1 Score (Macro): 0.04669823730597211\n",
            "Results for num_topics = 15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      三十三剑客图       0.00      0.00      0.00         4\n",
            "       书剑恩仇录       0.00      0.00      0.00         9\n",
            "         侠客行       0.00      0.00      0.00        12\n",
            "       倚天屠龙记       0.00      0.00      0.00        17\n",
            "        天龙八部       0.00      0.00      0.00        29\n",
            "       射雕英雄传       0.25      0.12      0.16        17\n",
            "       白马啸西风       0.00      0.00      0.00         1\n",
            "         碧血剑       0.00      0.00      0.00        17\n",
            "        神雕侠侣       0.00      0.00      0.00        23\n",
            "        笑傲江湖       0.00      0.00      0.00        29\n",
            "         连城诀       0.00      0.00      0.00         5\n",
            "        雪山飞狐       0.00      0.00      0.00         2\n",
            "        飞狐外传       0.00      0.00      0.00        11\n",
            "         鹿鼎记       0.12      0.92      0.22        24\n",
            "\n",
            "    accuracy                           0.12       200\n",
            "   macro avg       0.03      0.07      0.03       200\n",
            "weighted avg       0.04      0.12      0.04       200\n",
            "\n",
            "Accuracy: 0.12\n",
            "F1 Score (Macro): 0.026834733893557422\n",
            "Results for num_topics = 20:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      三十三剑客图       0.00      0.00      0.00         1\n",
            "       书剑恩仇录       0.00      0.00      0.00        17\n",
            "         侠客行       0.00      0.00      0.00         5\n",
            "       倚天屠龙记       0.00      0.00      0.00        21\n",
            "        天龙八部       0.18      1.00      0.31        36\n",
            "       射雕英雄传       1.00      0.05      0.09        21\n",
            "       白马啸西风       0.00      0.00      0.00         1\n",
            "         碧血剑       0.00      0.00      0.00         7\n",
            "        神雕侠侣       0.50      0.06      0.10        18\n",
            "        笑傲江湖       0.00      0.00      0.00        18\n",
            "         越女剑       0.00      0.00      0.00         1\n",
            "         连城诀       0.00      0.00      0.00         6\n",
            "        雪山飞狐       0.00      0.00      0.00         2\n",
            "        飞狐外传       0.00      0.00      0.00         7\n",
            "         鸳鸯刀       0.00      0.00      0.00         1\n",
            "         鹿鼎记       0.00      0.00      0.00        38\n",
            "\n",
            "    accuracy                           0.19       200\n",
            "   macro avg       0.11      0.07      0.03       200\n",
            "weighted avg       0.18      0.19      0.07       200\n",
            "\n",
            "Accuracy: 0.19\n",
            "F1 Score (Macro): 0.03124512290284822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-1"
      ],
      "metadata": {
        "id": "ghW-AN3ctcK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from sklearn.svm import SVC  # 以SVM作为分类器示例\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import random\n",
        "import string\n",
        "from gensim import corpora, models\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def stopwords(file_path):\n",
        "    stop_words = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        stop_words.extend([word.strip('\\n') for word in f.readlines()])\n",
        "    return stop_words\n",
        "\n",
        "def preprocess_corpus(text, cn_stopwords):\n",
        "    for tmp_char in cn_stopwords:\n",
        "        text = text.replace(tmp_char, \"\")\n",
        "    return text\n",
        "\n",
        "def extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value):\n",
        "    result = []\n",
        "    total_paragraphs_count = sum(len(corpus_dict[novel]) for novel in corpus_dict)\n",
        "\n",
        "    if total_paragraphs_count < num_paragraphs:\n",
        "        print(f\"Warning: Only {total_paragraphs_count} paragraphs available in the corpus. Requested {num_paragraphs} will be returned.\")\n",
        "        num_paragraphs = total_paragraphs_count\n",
        "\n",
        "    # 统计每个小说的段落数量，用于均匀抽取\n",
        "    paragraph_counts = {novel: len(paragraphs) for novel, paragraphs in corpus_dict.items()}\n",
        "    # 均匀抽取指定数量的段落\n",
        "    for _ in range(num_paragraphs):\n",
        "        # 随机选择一个小说\n",
        "        novel = random.choices(list(corpus_dict.keys()), weights=[count / total_paragraphs_count for count in paragraph_counts.values()], k=1)[0]\n",
        "        # 从该小说中随机抽取一个段落\n",
        "        paragraphs = corpus_dict[novel]\n",
        "        paragraphs = re.split(r'\\n\\u3000\\u3000', paragraphs)\n",
        "        paragraph = random.choice(paragraphs)\n",
        "\n",
        "        tokens = list(jieba.cut(paragraph))\n",
        "        result.append((tokens, novel, k_value))\n",
        "    return result\n",
        "\n",
        "def LDA(processed_data, num_topics=10):\n",
        "    X = [item[0] for item in processed_data]  # 段落文本列表\n",
        "    y = [item[1] for item in processed_data]  # 段落所属小说标签列表\n",
        "\n",
        "    # 训练集和测试集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 训练LDA模型\n",
        "    dictionary = corpora.Dictionary(X_train)\n",
        "    lda_corpus_train = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_train]\n",
        "    lda = models.LdaModel(corpus=lda_corpus_train, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "    train_topic_distribution = lda.get_document_topics(lda_corpus_train)\n",
        "\n",
        "    X_train_lda = np.zeros((len(X_train), num_topics))\n",
        "    for i in range(len(train_topic_distribution)):\n",
        "        tmp_topic_distribution = train_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_train_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "    classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "    lda_corpus_test = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_test]\n",
        "    test_topic_distribution = lda.get_document_topics(lda_corpus_test)\n",
        "    X_test_lda = np.zeros((len(X_test), num_topics))\n",
        "    for i in range(len(test_topic_distribution)):\n",
        "        tmp_topic_distribution = test_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_test_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    y_pred = classifier.predict(X_test_lda)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    return {'accuracy': accuracy, 'f1_macro': f1_macro}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    stopwords_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/stopwords-zh.txt'\n",
        "    corpus_folder_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/chinese_corpus/'\n",
        "\n",
        "    # 加载停用词\n",
        "    cn_stopwords = stopwords(stopwords_file_path)\n",
        "\n",
        "    # 读取语料库\n",
        "    corpus_dict = {}  # Dictionary to store novel titles and contents\n",
        "    for file_name in os.listdir(corpus_folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            novel_title = os.path.splitext(file_name)[0]  # Extract novel title from file name\n",
        "            file_path = os.path.join(corpus_folder_path, file_name)  # Construct full file path\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                novel_content = f.read()\n",
        "            corpus_dict[novel_title] = novel_content\n",
        "\n",
        "    # 参数\n",
        "    num_paragraphs = 1000\n",
        "    k_value = 3000  # Choose the desired token count\n",
        "\n",
        "    # 不同的主题数量\n",
        "    topic_numbers = [5, 10, 15, 20]\n",
        "\n",
        "    results = []\n",
        "\n",
        "\n",
        "    for num_topics in topic_numbers:\n",
        "        print(f\"Results for num_topics = {num_topics}:\")\n",
        "\n",
        "\n",
        "        processed_data = extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value)\n",
        "        result = LDA(processed_data, num_topics)\n",
        "\n",
        "\n",
        "        results.append({'Num Topics': num_topics, 'Accuracy': result['accuracy'], 'F1 Score (Macro)': result['f1_macro']})\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "    excel_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/classification_results.xlsx'\n",
        "    df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "    print(\"Results saved to Excel file:\", excel_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeBCIYwrtf_W",
        "outputId": "d6302156-fb62-4d36-be44-62b30d7bca15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for num_topics = 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for num_topics = 10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for num_topics = 15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for num_topics = 20:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to Excel file: ./mount/My Drive/Colab Notebooks/BH/1-2/DL/2/classification_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-2"
      ],
      "metadata": {
        "id": "PAaSpiyVvaSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from sklearn.svm import SVC  # 以SVM作为分类器示例\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import random\n",
        "import string\n",
        "from gensim import corpora, models\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_stopwords(file_path):\n",
        "    stop_words = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        stop_words.extend([word.strip('\\n') for word in f.readlines()])\n",
        "    return stop_words\n",
        "\n",
        "def preprocess_corpus(text, cn_stopwords, unit='word'):\n",
        "    processed_text = ''\n",
        "    if unit == 'word':\n",
        "        for tmp_char in cn_stopwords:\n",
        "            text = text.replace(tmp_char, \"\")\n",
        "        processed_text = ' '.join(jieba.cut(text))\n",
        "    elif unit == 'char':\n",
        "        processed_text = re.sub(r'\\s+', '', text)  # 移除空白字符\n",
        "    return processed_text\n",
        "\n",
        "def extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value, unit='word'):\n",
        "    result = []\n",
        "    total_paragraphs_count = sum(len(corpus_dict[novel]) for novel in corpus_dict)\n",
        "\n",
        "    if total_paragraphs_count < num_paragraphs:\n",
        "        print(f\"Warning: Only {total_paragraphs_count} paragraphs available in the corpus. Requested {num_paragraphs} will be returned.\")\n",
        "        num_paragraphs = total_paragraphs_count\n",
        "\n",
        "    paragraph_counts = {novel: len(paragraphs) for novel, paragraphs in corpus_dict.items()}\n",
        "    # 均匀抽取指定数量的段落\n",
        "    for _ in range(num_paragraphs):\n",
        "        # 随机选择一个小说\n",
        "        novel = random.choices(list(corpus_dict.keys()), weights=[count / total_paragraphs_count for count in paragraph_counts.values()], k=1)[0]\n",
        "        # 从该小说中随机抽取一个段落\n",
        "        paragraphs = corpus_dict[novel]\n",
        "        paragraphs = re.split(r'\\n\\u3000\\u3000', paragraphs)\n",
        "        paragraph = random.choice(paragraphs)\n",
        "\n",
        "        if unit == 'word':\n",
        "            tokens = list(jieba.cut(paragraph))\n",
        "        elif unit == 'char':\n",
        "            tokens = list(paragraph)\n",
        "        result.append((tokens, novel, k_value))\n",
        "    return result\n",
        "\n",
        "\n",
        "def LDA(processed_data, num_topics=10):\n",
        "    X = [item[0] for item in processed_data]  # 段落文本列表\n",
        "    y = [item[1] for item in processed_data]  # 段落所属小说标签列表\n",
        "\n",
        "    # 训练集和测试集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 训练LDA模型\n",
        "    dictionary = corpora.Dictionary(X_train)\n",
        "    lda_corpus_train = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_train]\n",
        "    lda = models.LdaModel(corpus=lda_corpus_train, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "    train_topic_distribution = lda.get_document_topics(lda_corpus_train)\n",
        "\n",
        "    X_train_lda = np.zeros((len(X_train), num_topics))\n",
        "    for i in range(len(train_topic_distribution)):\n",
        "        tmp_topic_distribution = train_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_train_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "    classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "    lda_corpus_test = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_test]\n",
        "    test_topic_distribution = lda.get_document_topics(lda_corpus_test)\n",
        "    X_test_lda = np.zeros((len(X_test), num_topics))\n",
        "    for i in range(len(test_topic_distribution)):\n",
        "        tmp_topic_distribution = test_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_test_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    y_pred = classifier.predict(X_test_lda)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    return {'accuracy': accuracy, 'f1_macro': f1_macro}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    stopwords_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/stopwords-zh.txt'\n",
        "    corpus_folder_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/chinese_corpus/'\n",
        "\n",
        "    #\n",
        "    cn_stopwords = load_stopwords(stopwords_file_path)\n",
        "\n",
        "    # 读取语料库\n",
        "    corpus_dict = {}  # Dictionary to store novel titles and contents\n",
        "    for file_name in os.listdir(corpus_folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            novel_title = os.path.splitext(file_name)[0]  # Extract novel title from file name\n",
        "            file_path = os.path.join(corpus_folder_path, file_name)  # Construct full file path\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                novel_content = f.read()\n",
        "            corpus_dict[novel_title] = novel_content\n",
        "\n",
        "    # 参数\n",
        "    num_paragraphs = 1000\n",
        "    k_value = 3000  # Choose the desired token count\n",
        "\n",
        "    # 不同的主题数量\n",
        "    topic_numbers = [5, 10, 15, 20]\n",
        "\n",
        "    units = ['word', 'char']\n",
        "    # 不同的基本单元\n",
        "\n",
        "    results = []  # 存储结果\n",
        "\n",
        "    # 遍历不同的基本单元\n",
        "    for unit in units:\n",
        "        print(f\"Results for unit = {unit}:\")\n",
        "\n",
        "        # 遍历不同的主题数量\n",
        "        for num_topics in topic_numbers:\n",
        "            print(f\"  Results for num_topics = {num_topics}:\")\n",
        "\n",
        "            # 执行主题建模和分类任务\n",
        "            processed_data = extract_paragraphs_and_labels(corpus_dict, num_paragraphs, k_value, unit=unit)\n",
        "            result = LDA(processed_data, num_topics)\n",
        "\n",
        "\n",
        "            results.append({'Unit': unit, 'Num Topics': num_topics, 'Accuracy': result['accuracy'], 'F1 Score (Macro)': result['f1_macro']})\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # 将 DataFrame 保存到 Excel 文件\n",
        "    excel_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/classification_results_with_units.xlsx'\n",
        "    df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "    print(\"Results saved to Excel file:\", excel_file_path)\n"
      ],
      "metadata": {
        "id": "dU8CA_WSvbVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-3"
      ],
      "metadata": {
        "id": "5vjSvbSS9b56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "import random\n",
        "import string\n",
        "from gensim import corpora, models\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_stopwords(file_path):\n",
        "    stop_words = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        stop_words.extend([word.strip('\\n') for word in f.readlines()])\n",
        "    return stop_words\n",
        "\n",
        "def preprocess_corpus(text, cn_stopwords):\n",
        "    for tmp_char in cn_stopwords:\n",
        "        text = text.replace(tmp_char, \"\")\n",
        "    return text\n",
        "\n",
        "def extract_paragraphs_and_labels(corpus_dict, num_paragraphs, short_threshold, long_threshold):\n",
        "    result = []\n",
        "    total_paragraphs_count = sum(len(corpus_dict[novel]) for novel in corpus_dict)\n",
        "\n",
        "    if total_paragraphs_count < num_paragraphs:\n",
        "        print(f\"Warning: Only {total_paragraphs_count} paragraphs available in the corpus. Requested {num_paragraphs} will be returned.\")\n",
        "        num_paragraphs = total_paragraphs_count\n",
        "\n",
        "    # 统计每个小说的段落数量，用于均匀抽取\n",
        "    paragraph_counts = {novel: len(paragraphs) for novel, paragraphs in corpus_dict.items()}\n",
        "\n",
        "    # 均匀抽取指定数量的段落\n",
        "    for _ in range(num_paragraphs):\n",
        "        # 随机选择一个小说\n",
        "        novel = random.choices(list(corpus_dict.keys()), weights=[count / total_paragraphs_count for count in paragraph_counts.values()], k=1)[0]\n",
        "        # 从该小说中随机抽取一个段落\n",
        "        paragraphs = corpus_dict[novel]\n",
        "        paragraphs = re.split(r'\\n\\u3000\\u3000', paragraphs)\n",
        "        paragraph = random.choice(paragraphs)\n",
        "\n",
        "        tokens = list(jieba.cut(paragraph))\n",
        "\n",
        "        if len(tokens) <= short_threshold:\n",
        "            k_value = random.choice(range(short_threshold, long_threshold + 1))\n",
        "        else:\n",
        "            k_value = random.choice(range(long_threshold + 1, 2 * long_threshold + 1))\n",
        "\n",
        "        result.append((tokens, novel, k_value))\n",
        "    return result\n",
        "\n",
        "def LDA(processed_data, num_topics=10):\n",
        "    X = [item[0] for item in processed_data]  # 段落文本列表\n",
        "    y = [item[1] for item in processed_data]  # 段落所属小说标签列表\n",
        "\n",
        "    # 划分训练集和测试集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 训练LDA模型\n",
        "    dictionary = corpora.Dictionary(X_train)\n",
        "    lda_corpus_train = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_train]\n",
        "    lda = models.LdaModel(corpus=lda_corpus_train, id2word=dictionary, num_topics=num_topics)\n",
        "\n",
        "    train_topic_distribution = lda.get_document_topics(lda_corpus_train)\n",
        "\n",
        "    X_train_lda = np.zeros((len(X_train), num_topics))\n",
        "    for i in range(len(train_topic_distribution)):\n",
        "        tmp_topic_distribution = train_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_train_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    classifier = SVC(kernel='linear', C=1, random_state=42)\n",
        "    classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "    lda_corpus_test = [dictionary.doc2bow(tmp_doc) for tmp_doc in X_test]\n",
        "    test_topic_distribution = lda.get_document_topics(lda_corpus_test)\n",
        "    X_test_lda = np.zeros((len(X_test), num_topics))\n",
        "    for i in range(len(test_topic_distribution)):\n",
        "        tmp_topic_distribution = test_topic_distribution[i]\n",
        "        for j in range(len(tmp_topic_distribution)):\n",
        "            X_test_lda[i][tmp_topic_distribution[j][0]] = tmp_topic_distribution[j][1]\n",
        "\n",
        "    y_pred = classifier.predict(X_test_lda)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    return {'accuracy': accuracy, 'f1_macro': f1_macro}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 文件路径\n",
        "    stopwords_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/stopwords-zh.txt'\n",
        "    corpus_folder_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/chinese_corpus/'\n",
        "\n",
        "    # 停用词\n",
        "    cn_stopwords = load_stopwords(stopwords_file_path)\n",
        "\n",
        "    # 语料库\n",
        "    corpus_dict = {}  # Dictionary to store novel titles and contents\n",
        "    for file_name in os.listdir(corpus_folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            novel_title = os.path.splitext(file_name)[0]  # Extract novel title from file name\n",
        "            file_path = os.path.join(corpus_folder_path, file_name)  # Construct full file path\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                novel_content = f.read()\n",
        "            corpus_dict[novel_title] = novel_content\n",
        "\n",
        "    # 参数\n",
        "    num_paragraphs = 1000\n",
        "    short_threshold = 100\n",
        "    long_threshold = 500\n",
        "    num_topics = 10\n",
        "\n",
        "    # 定义不同的 K 值范围\n",
        "    k_values_short = [20, 50, 100]\n",
        "    k_values_long = [500, 1000, 2000]\n",
        "\n",
        "    results = []  # 存储结果\n",
        "\n",
        "    # 短文本\n",
        "    for k_short in k_values_short:\n",
        "        print(f\"Results for K (Short Text) = {k_short}:\")\n",
        "\n",
        "        # 执行主题建模和分类任务\n",
        "        processed_data_short = extract_paragraphs_and_labels(corpus_dict, num_paragraphs, short_threshold, long_threshold)\n",
        "        result_short = LDA(processed_data_short, num_topics)\n",
        "\n",
        "        # 存储结果\n",
        "        results.append({'K (Short Text)': k_short, 'Accuracy (Short Text)': result_short['accuracy'], 'F1 Score (Macro) (Short Text)': result_short['f1_macro']})\n",
        "\n",
        "    # 长文本\n",
        "    for k_long in k_values_long:\n",
        "        print(f\"Results for K (Long Text) = {k_long}:\")\n",
        "\n",
        "        # 执行主题建模和分类任务\n",
        "        processed_data_long = extract_paragraphs_and_labels(corpus_dict, num_paragraphs, short_threshold, long_threshold)\n",
        "        result_long = LDA(processed_data_long, num_topics)\n",
        "\n",
        "        # 存储结果\n",
        "        results.append({'K (Long Text)': k_long, 'Accuracy (Long Text)': result_long['accuracy'], 'F1 Score (Macro) (Long Text)': result_long['f1_macro']})\n",
        "\n",
        "    # 将结果转换为 DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # 将 DataFrame 保存到 Excel 文件\n",
        "    excel_file_path = './mount/My Drive/Colab Notebooks/BH/1-2/DL/2/topic_model_results.xlsx'\n",
        "    df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "    print(\"Results saved to Excel file:\", excel_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3r3HF9R9ek8",
        "outputId": "0fe04cf3-064b-4e53-db3b-4c6c3d9ded16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for K (Short Text) = 50:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for K (Short Text) = 100:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for K (Long Text) = 500:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for K (Long Text) = 1000:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for K (Long Text) = 2000:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to Excel file: ./mount/My Drive/Colab Notebooks/BH/1-2/DL/2/topic_model_results.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}